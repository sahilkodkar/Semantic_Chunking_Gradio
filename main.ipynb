{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube # Video Download\n",
    "from moviepy.editor import AudioFileClip  # For audio extraction\n",
    "import whisper # For transcribing audio\n",
    "\n",
    "\n",
    "# Downloading the YouTube Video and Extracting Audio\n",
    "def download_and_extract_audio(youtube_url, output_path=\"Extracted_Audio.mp3\"):\n",
    "    yt = YouTube(youtube_url)\n",
    "    video_stream = yt.streams.filter(only_audio=True).first()\n",
    "    video_stream.download(filename=\"YouTube_Video.mp4\")\n",
    "\n",
    "    audio_clip = AudioFileClip(\"YouTube_Video.mp4\")\n",
    "    audio_clip.write_audiofile(output_path)\n",
    "    audio_clip.close()\n",
    "\n",
    "download_and_extract_audio(\"#LINK\")\n",
    "\n",
    "# Loading Whisper Model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Transcribing Audio\n",
    "result = model.transcribe(\"Extracted_Audio.mp3\")\n",
    "\n",
    "transcription = result['text']\n",
    "segments = result['segments']\n",
    "\n",
    "\n",
    "# Time Align Transcript with Audio & Semantic Chunking\n",
    "\n",
    "\n",
    "def create_semantic_chunks(segments, max_chunk_length=15):\n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    current_chunk = {\"text\": \"\", \"start_time\": None, \"end_time\": None}\n",
    "\n",
    "    # Creating semantic chunks of the transcription based on the specified maximum chunk length.\n",
    "\n",
    "    for segment in segments:\n",
    "        start_time = segment['start']\n",
    "        end_time = segment['end']\n",
    "        text = segment['text']\n",
    "\n",
    "        if current_chunk[\"start_time\"] is None:\n",
    "            current_chunk[\"start_time\"] = start_time\n",
    "\n",
    "        if current_chunk[\"end_time\"] is None or (end_time - current_chunk[\"start_time\"]) <= max_chunk_length:\n",
    "            current_chunk[\"text\"] += \" \" + text\n",
    "            current_chunk[\"end_time\"] = end_time\n",
    "        else:\n",
    "            chunk_id += 1\n",
    "            chunks.append({\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"chunk_length\": current_chunk[\"end_time\"] - current_chunk[\"start_time\"],\n",
    "                \"text\": current_chunk[\"text\"].strip(),\n",
    "                \"start_time\": current_chunk[\"start_time\"],\n",
    "                \"end_time\": current_chunk[\"end_time\"]\n",
    "            })\n",
    "            current_chunk = {\"text\": text, \"start_time\": start_time, \"end_time\": end_time}\n",
    "\n",
    "    if current_chunk[\"text\"]:\n",
    "        chunk_id += 1\n",
    "        chunks.append({\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"chunk_length\": current_chunk[\"end_time\"] - current_chunk[\"start_time\"],\n",
    "            \"text\": current_chunk[\"text\"].strip(),\n",
    "            \"start_time\": current_chunk[\"start_time\"],\n",
    "            \"end_time\": current_chunk[\"end_time\"]\n",
    "        })\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunks = create_semantic_chunks(segments)\n",
    "\n",
    "chunks_output = [\n",
    "    {\n",
    "        \"chunk_id\": chunk[\"chunk_id\"],\n",
    "        \"chunk_length\": chunk[\"chunk_length\"],\n",
    "        \"text\": chunk[\"text\"],\n",
    "        \"start_time\": chunk[\"start_time\"],\n",
    "        \"end_time\": chunk[\"end_time\"]\n",
    "    }\n",
    "    for chunk in chunks\n",
    "]\n",
    "\n",
    "chunks_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def process_video(youtube_url):\n",
    "    download_and_extract_audio(youtube_url)\n",
    "    result = model.transcribe(\"Extracted_Audio.mp3\")\n",
    "    segments = result['segments']\n",
    "    chunks = create_semantic_chunks(segments)\n",
    "\n",
    "    output_list = [\n",
    "        {\n",
    "            \"chunk_id\": chunk[\"chunk_id\"],\n",
    "            \"chunk_length\": chunk[\"chunk_length\"],\n",
    "            \"text\": chunk[\"text\"],\n",
    "            \"start_time\": chunk[\"start_time\"],\n",
    "            \"end_time\": chunk[\"end_time\"]\n",
    "        }\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    return output_list\n",
    "\n",
    "# Gradio Interface\n",
    "\n",
    "iface = gr.Interface(fn=process_video, inputs=\"text\", outputs=\"json\")\n",
    "iface.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
